#DOCKER CONFIG
#_______________________________________________________________________________________________________________
environment {
  mode = "constant-rate"
  mode = ${?MODE}
  is.running.in.docker = "true"
}

general {
  last.stage = "3"
  last.stage = ${?LAST_STAGE}
  partitions = 2
  partitions = ${?PARTITIONS}
  stream.source {
    volume = "1"
    volume = ${?DATA_VOLUME}
  }
}

kafka {
  groupid = "ndwgroup"
  bootstrap.servers = "kafka:9092"
  bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}
  zookeeper.server = "zookeeper:2181"
  zookeeper.server = ${?ZOOKEEPER_SERVER}
  output.topic = "metrics"
  output.topic = ${?TOPICNAME}
  auto.offset.reset.strategy = "latest"
  auto.offset.reset.strategy = ${?KAFKA_AUTO_OFFSET_RESET_STRATEGY}
  flow.topic = "ndwflow"
  flow.topic = ${?FLOWTOPIC}
  speed.topic = "ndwspeed"
  speed.topic = ${?SPEEDTOPIC}
}

hdfs {
  active.name.node = ""
}

monitoring {
  graphite.host = "graphite_grafana"
  graphite.port = 2003
  print.output = true
}

spark {
  master = "local[4]"
  checkpoint.dir = "/opt/docker/checkpointdir/"
  default.parallelism = 1
  default.parallelism = ${?DEFAULT_PARALLELISM}
  sql.shuffle.partitions = 1
  sql.shuffle.partitions = ${?SQL_SHUFFLE_PARTITIONS}
}

storm {
  workers = 4
}

flink {
  checkpoint.dir = "file:///opt/flink/checkpointdir/"
  partitions = "20"
  partitions = ${?NUM_PARTITIONS}
}

kafkastreams {
  checkpoint.dir = "./kafka-logs/"
  streams.threads.per.instance = 1
  streams.threads.per.instance = ${?NUM_THREADS_PER_INSTANCE}
}